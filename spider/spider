#!/bin/bash -u
#
# spider - ConquerClub API data downloader
#
#    Copyright (C) 2015 Rodrigo Silva (MestreLion) <conquerclub@rodrigosilva.com>
#
#    This program is free software: you can redistribute it and/or modify
#    it under the terms of the GNU General Public License as published by
#    the Free Software Foundation, either version 3 of the License, or
#    (at your option) any later version.
#
#    This program is distributed in the hope that it will be useful,
#    but WITHOUT ANY WARRANTY; without even the implied warranty of
#    MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
#    GNU General Public License for more details.
#
#    You should have received a copy of the GNU General Public License
#    along with this program. If not, see <http://www.gnu.org/licenses/gpl.html>

# TODO: automatic repair
# TODO: automatically update last page


# Default options -------------------------------------------------------------

page=1
batches=5
mode=gamelist
jobs=20
args=10
delay=2.0
ppb=1000
ppp=1000  # players per page

workdir='.'

verbose=1
yes=0
logging=1


# Constants and other globals -------------------------------------------------

myname=${0##*/}
mydir=$(dirname "$(readlink -f "$0")")

urlmain="http://www.conquerclub.com"


# Generic helper functions ----------------------------------------------------

bold()    { tput bold; printf '%s' "$@"; tput sgr0; }
red()     { tput setaf 1; bold "$@"; }
green()   { tput setaf 2; bold "$@"; }

fatal()   { if (($#)); then echo "$(red '* ' "$@")" >&2; fi; exit 1; }
message() { if ((verbose)); then echo "$(green '* ' "$(curtime) - $@")"; fi; }
warning() { if ((verbose)); then echo "$(red '* ' "$@")"; fi; }
argerr()  { echo $(red "* ${1:-error}") >&2; usage 1; }
invalid() { argerr "invalid option: ${1:-}" ; }
missing() { argerr "missing ${2:+$2 }argument${1:+ from $1}." ; }
integer() { [[ "$1" ]] || missing "${2:-}" "${3-NUM}"; [[ "$1" != *[!0-9]* ]] ||
            argerr "'$1'${2:+ in $2} is not an integer."; }
numeric() { [[ "$1" ]] || missing "${2:-}" "${3-NUM}"; re='^[0-9]+([.][0-9]+)?$'
            [[ "$1" =~ $re ]] || argerr "'${1:-}'${2:+ in $2} is not a number."; }
curtime() { date --rfc-3339=seconds; }
exists()  { type "$@" >/dev/null 2>&1; }
min()     { if (( "$1" < "$2" )); then echo "$1"; else echo "$2"; fi; }
max()     { if (( "$1" > "$2" )); then echo "$1"; else echo "$2"; fi; }

ceildiv() {
	local num=${1:-0}
	local div=${2:-1}
	echo $(( (num + div - 1) / div ))
}

ceilnear() {
	local num=${1:-0}
	local near=${2:-1000}
	echo $(( $(ceildiv "$num" "$near") * near ))
}

confirm()
{
	local msg=$(bold "${@:-"Confirm?"}")
	local default=$(bold "NO")
	local reply

	if ! ((yes)); then
		read -p "* $msg (y/n, default $default): " reply
		reply="${reply:-$default}"
		case "$reply" in
			[Yy]*) ;;
			*) message "Canceled"; exit 1;;
		esac
	fi
}

require() {
	local cmd="$1"
	shift
	local packages="${@:-$cmd}"
	local reqmsg="$myname requires '$cmd'"

	if exists "$cmd"; then return; fi

	exists apt-get || fatal "$reqmsg, please install it and try again."
	confirm "$reqmsg, want to install packages?" \
		" (need administrator priviledges)"
	message "Installing package ${packages[@]}"
	sudo apt-get install -y "${packages[@]}" ||
		fatal "Error installing packages (did you cancel it?)"
}

benchmark() {
	local start=$1
	local num=$2
	local name=${3:-page}
	local secs=$(($(date +%s) - start))

	echo "$secs seconds" \
		"($(date +%T -d"@$secs" -u))," \
		$(awk -v s="$secs" -v n="$num" 'BEGIN{print s/n; exit}') \
		"seconds per $name"
}

logger() {
	if !((logging)); then return; fi
	if [[ "${logfile:-}" ]]; then
		echo "$(curtime) - $@" >> "${logfile}"
	fi
}

logmsg() { logger "$@"; message "$@"; }


# Main functions --------------------------------------------------------------

usage() {
	cat <<-USAGE
	Usage: $myname [options]
	USAGE
	if [[ "${1:-}" ]] ; then
		cat >&2 <<- USAGE
		Try '$myname --help' for more information.
		USAGE
		exit 1
	fi
	cat <<-USAGE

	ConquerClub API data downloader

	General options:
	  -h|--help  - show this page
	  -q|--quiet - do not output informative messages or progress
	  -y|--yes   - automatically answer "yes" to all questions

	Download options:
	  --mode MODE
	             what data to download. Current options are 'gamelist',
	             'tournamentlist'. [default: '$mode']

	  --page NUM
	             absolute page to start downloading. [default: $page]

	  --batches NUM
	             number of batches to run. Zero means all batches until
	             last page*. [default: $batches]

	  --ppb NUM
	             number of pages per batch. [default: $ppb]

	  --jobs NUM
	             how many simultaneous fetching jobs to run in parallel.
	             If your parallel version does not support job delay, jobs
	             are limited to a maximum of 10 (see --delay).
	             [default: $jobs]

	  --args NUM
	             how many pages to fetch sequentially on each job.
	             Increasing args make each job take longer, but each job is
	             a single server connection, so it benefits from keep_alive
	             HTTP headers. [default: $args]

	  --delay NUM
	             delay between starting new simultaneous jobs, in seconds.
	             Prevents overloading the server with too many simultaneous
	             requests. The deault is adequate for the "maximum of 5
	             requests per 10 seconds" API policy. Requires parallel
	             version 20121222+. Fractional numbers are accepted.
	             [default: $delay]

	  --no-log
	            do not create log files. By default $myname creates a master
	            log file at '<WORKDIR>/$myname-<MODE>-<TIMESTAMP>.log', and
	            also a parallel log for each completed batch.

	  --work-dir DIR
	            target root directory to download files. Pages will be
	            downloaded to <WORKDIR>/<MODE>/current and then moved to
	            <WORKDIR>/<MODE>/pages/<BATCH> once completed. All dirs will
	            be created if necessary.
	            [default: $workdir]

	* - Not fully implemented yet

	Copyright (C) 2015 Rodrigo Silva (MestreLion) <linux@rodrigosilva.com>
	License: GPLv3 or later. See <http://www.gnu.org/licenses/gpl.html>
	USAGE
	exit 0
}


# Command-line arguments ------------------------------------------------------

for arg in "$@"; do [[ "$arg" == "-h" || "$arg" == "--help" ]] && usage ; done
while (( $# )); do
	case "$1" in
	--page=*        ) page=${1#*=}           ;;
	--batches=*     ) batches=${1#*=}        ;;
	--mode=*        ) mode=${1#*=}           ;;
	--jobs=*        ) jobs=${1#*=}           ;;
	--args=*        ) args=${1#*=}           ;;
	--delay=*       ) delay=${1#*=}          ;;
	--ppb=*         ) ppb=${1#*=}            ;;
	--workdir=*     ) workdir=${1#*=}        ;;

	--page          ) shift ; page=${1:-}    ;;
	--batches       ) shift ; batches=${1:-} ;;
	--mode          ) shift ; mode=${1:-}    ;;
	--jobs          ) shift ; jobs=${1:-}    ;;
	--args          ) shift ; args=${1:-}    ;;
	--delay         ) shift ; delay=${1:-}   ;;
	--ppb           ) shift ; ppb=${1:-}     ;;
	--workdir       ) shift ; workdir=${1:-} ;;

	-q|--quiet      ) verbose=0              ;;
	-y|--yes        ) yes=1                  ;;
	--no-log        ) logging=0              ;;

	*               ) invalid "$1"           ;;
	esac
	shift
done

[[ "$mode" ]] || missing "--mode" "MODE"

integer "$page"    "--page"
integer "$batches" "--batches"
integer "$jobs"    "--jobs"
integer "$args"    "--args"
integer "$ppb"     "--ppb"
numeric "$delay"   "--delay"

if ((ppb <= 0)); then argerr "pages per batch must be greater than 0"; fi

case "$mode" in
gamelist)
	urlapi="$urlmain/api.php?mode=gamelist&events=Y&names=Y&page="
	pages=68720  # total number of pages
;;
tournamentlist)
	urlapi="$urlmain/api.php?mode=tournamentlist&names=Y&page="
	pages=267  # total number of pages
;;
player)
	urlapi="$urlmain/api.php?mode=player&u="
	players=745839  # max player ID, not all IDs are valid (724742 valid)
	# list=$(seq -s, $((players - ppp)) "$players")
	# server limit: 8191 chars, 'GET /api.php?...745838,745839 HTTP/1.1'
	# 8191-37+1[last comma]/(6+1[id length+comma]) = 1165 players exactly
	# 1019 when id gets to 7 digits (soon). 1000 is safe for the foreseable
	# future
	pages=$(($(ceilnear "$players" "$ppp") / ppp))

	# avoid "filename too long" wget bug. fixed in wget 1.15 (ubuntu 14.04+)
	# see https://bugs.debian.org/cgi-bin/bugreport.cgi?bug=672131
	args=1
;;
*)
	fatal "unknown mode: $mode"
;;
esac

workdir=$(readlink -f "$workdir")
logfile=${workdir}/${myname}-${mode}-$(date +%Y%m%d%H%M%S).log
outdir=${workdir}/${mode}
curdir=${outdir}/current
pagedir=${outdir}/pages


# Requirements ----------------------------------------------------------------

require parallel  parallel
require 7z        p7zip-full


# Parallel set-up -------------------------------------------------------------

parallelargs=(--gnu)

# Setup delay, only available in recent verions of parallel (20121222 onwards)
if echo | parallel --delay "$delay" >/dev/null 2>&1; then
	parallelargs+=(--delay "$delay")
else
	warning "Your 'parallel' version does not suport job delay." \
		" Limiting jobs to 10"
	jobs=$(max "$jobs" 10)
fi

# If running a recent version of parallel that contains the BibTeX notice,
# and it's not silenced yet, display the notice once so the user can silence it,
# as per parallel's author request.
# Adding --no-notice also works, but it's rude. Let's support the author!
if echo | parallel --no-notice >/dev/null 2>&1 &&
	! [[ -f "$HOME"/.parallel/will-cite ]]
then
	parallel --bibtex
fi

if ((verbose)); then
	parallelargs+=(--progress)
fi


# Main logic and procedures ---------------------------------------------------

if ((verbose)); then
	logmsg "Starting $myname with the following options:"
	logmsg "	Data mode:         $mode"
	logmsg "	Start Page:        $page"
	logmsg "	Number of batches: $batches"
	logmsg "	Simultaneous jobs: $jobs"
	logmsg "	Job delay:         $delay"
	logmsg "	Pages per job:     $args"
	logmsg "	Pages per batch:   $ppb"
	logmsg "	Download dir:      $curdir"
fi

mkdir -p -- "$workdir" "$outdir" "$pagedir" "$curdir" &&
cd "$curdir" ||
fatal "could not create directories"

for batch in $(seq 1 "$batches"); do
	if [[ -f "stop" ]]; then
		logmsg "Stop requested"
		break
	fi

	# Calculate end page
	endpage=$(min "$pages" \
		$(min $((page + ppb - 1)) $(ceilnear "$page" "$ppb")))

	logmsg "Starting batch $batch of $batches, pages $page to $endpage"
	batchstart=$(date +%s)

	dirname=$(printf '%03d' $(((page-1)/ppb)))
	tag="${mode}-${dirname}-pages-${page}-${endpage}"

	parallelbatchargs=("${parallelargs[@]}")
	if ((logging)); then
		parallelbatchargs+=(--joblog "$tag".log)
	fi

	# download pages
	mkdir -p -- "$dirname"
	if [[ "$mode" == "player" ]]; then
		for playerpage in $(seq "$page" "$endpage"); do
			player=$((ppp * (playerpage - 1) + 1))
			endplayer=$(min "$players" $((player + ppp - 1)))
			echo "$playerpage"
			seq -s',' "$player" "$endplayer"
		done |
		parallel "${parallelbatchargs[@]}" \
			--jobs "$jobs" --max-replace-args 2 -- \
				wget -q -O "'${dirname}/${urlapi##*/}{1}'" \
					-- "'${urlapi}{2}'"
	else
		seq "$page" "$endpage" |
		parallel "${parallelbatchargs[@]}" \
			--jobs "$jobs" --max-replace-args "$args" -- \
				wget -qN -P "'$dirname'" -- "'${urlapi}{}'"
	fi
	sleep "${delay}"

	logmsg "Batch $batch finished: " \
		"$(benchmark $batchstart $((endpage - page + 1)))"

	# verify log
	if ((logging)); then
		if grep -qP '\t0\t0\t[^0E][0-9]*\t0\t' "$tag".log; then
			warning "Download errors found, check the master log!"
			logger "Download errors found," \
				" retry commands saved to repair file"
			awk -F'\t' 'NR==1{next} $7 !~ 0 {print $9}' \
				"$tag".log >> "${logfile%.*}".retry.log
		else
			mv "$tag".log "$outdir"/"$tag"-$(date +%Y%m%d%H%M%S).log
		fi
	fi

	# verify pages
	for pagefile in "$dirname"/"$(basename "$urlapi")"*; do
		tail -n 1 "$pagefile" | grep -q '</api>' ||
		{
			warning "Bad file found: $pagefile"
			logger "bad file: $pagefile"
		}
	done

	# move to workdir/mode/pages/999
	pagedirname="$pagedir"/"$dirname"
	pagefilepref="$pagedirname"/"$mode"-page
	mkdir -p -- "$pagedirname"
	for pagefile in "$dirname"/"$(basename "$urlapi")"*; do
		mv "$pagefile" "$pagefilepref"-"${pagefile##*=}".xml
	done
	rmdir --ignore-fail-on-non-empty -- "$dirname"

	# archive
	if ((endpage == pages)) ||
		[[ $(ls -A1 "$pagedirname"/*.xml | wc -l) == "$ppb" ]]
	then
		cd "$pagedirname"
		7z a "$workdir"/"$tag" -- *.xml >/dev/null &  # 7z is too chatty!
		cd - >/dev/null
	else
		# find missing
		for pagenum in $(seq "$ppb"); do
			abspage=$(( 10#$dirname * ppb + pagenum ))  # damn octal!
			wgetcmd=(wget -NP "$dirname" -- "${urlapi}${abspage}")
			if ! [[ -f "$pagefilepref"-"$abspage".xml ]]; then
				logger "still missing: $dirname	$abspage	${wgetcmd[@]}"
			fi
		done
	fi

	# get ready for next batch
	((page = endpage + 1))
	if ((page > pages)); then
		break
	fi
done

rmdir --ignore-fail-on-non-empty -- "$curdir"
message "Waiting for pending tasks..."
wait

logmsg "Done!"
message "Next page: $((page))"
